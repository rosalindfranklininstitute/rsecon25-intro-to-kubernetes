{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Deploying a Webservice with Kubernetes","text":"<p>This tutorial shows you how to deploy a web service with Kubernetes. We will cover:</p> <ul> <li>Why Kubernetes</li> <li>Kubernetes architecture</li> <li>Writing manifests</li> <li>Deploying apps</li> <li>Scaling</li> <li>Rolling updates</li> </ul>"},{"location":"kubernetes-architecture/","title":"Introduction to Kubernetes Architecture","text":""},{"location":"kubernetes-architecture/#overview","title":"Overview","text":"<p>Kubernetes is a powerful container orchestration platform that automates deployment, scaling, and management of containerized applications. Its architecture is divided into two main parts:</p> <ul> <li>Control Plane</li> <li>Worker Nodes</li> </ul>"},{"location":"kubernetes-architecture/#nodes","title":"Nodes","text":""},{"location":"kubernetes-architecture/#control-plane","title":"Control plane","text":"<p>The Control Plane is the brain of the Kubernetes cluster. It manages the cluster's state and makes decisions about scheduling, scaling, and responding to events. The Control Plane has individual components running as pods on the node, each responsible for various tasks. </p>"},{"location":"kubernetes-architecture/#key-components","title":"Key Components:","text":"<ul> <li> <p>API Server - Acts as the front-end for the Kubernetes control plane. All interactions (kubectl, dashboard, etc.) go through this RESTful API. <code>kube-apiserver-&lt;node-name&gt;</code></p> </li> <li> <p>Controller Manager - Runs controllers that handle routine tasks like node health checks, replication, and endpoint management. <code>kube-controller-manager-&lt;node-name&gt;</code></p> </li> <li> <p>Scheduler - Assigns newly created pods to nodes based on resource availability and constraints. <code>kube-scheduler-&lt;node-name&gt;</code></p> </li> <li> <p>etcd - A distributed key-value store that holds all cluster data (state, configuration, etc.). <code>etcd-&lt;node-name&gt;</code></p> </li> </ul>"},{"location":"kubernetes-architecture/#worker-nodes","title":"Worker Nodes","text":"<p>Worker nodes are where your application containers actually run. Each node has the following components:</p>"},{"location":"kubernetes-architecture/#key-components_1","title":"Key Components:","text":"<ul> <li> <p>Kubelet - An agent that runs on each node. It communicates with the API server and ensures containers are running as expected.</p> </li> <li> <p>Container Runtime - Software responsible for running containers (e.g., Docker, containerd).</p> </li> <li> <p>Kube-proxy - Handles network routing and load balancing for services within the cluster.</p> </li> </ul>"},{"location":"kubernetes-architecture/#basic-resources","title":"Basic resources","text":""},{"location":"kubernetes-architecture/#containers-the-building-blocks","title":"Containers: The Building Blocks","text":"<p>A container is a lightweight, standalone, executable package that includes everything needed to run a piece of software: code, runtime, libraries, and system tools.</p> <p>Why Containers?</p> <ul> <li>Portability: Runs the same across environments.</li> <li>Isolation: Each container runs independently.</li> <li>Efficiency: Uses fewer resources than virtual machines.</li> </ul>"},{"location":"kubernetes-architecture/#pods-the-smallest-deployable-unit-in-kubernetes","title":"Pods: The Smallest Deployable Unit in Kubernetes","text":"<p>A pod is a group of one or more containers that share storage, network, and a specification for how to run the containers.</p> <p>Key Characteristics:</p> <ul> <li>Containers in a pod share the same IP address and port space.</li> <li>Pods are ephemeral\u2014if a pod dies, Kubernetes can replace it.</li> <li>Typically, a pod contains a single container, but can include sidecars (e.g., logging or proxy containers).</li> </ul> <p>Analogy: Think of a pod as a wrapper around containers that Kubernetes can manage.</p>"},{"location":"kubernetes-architecture/#deployments-managing-application-lifecycle","title":"Deployments: Managing Application Lifecycle","text":"<p>A deployment is a Kubernetes object that manages a set of pods and ensures the desired number of replicas are running at all times.</p> <p>Features:</p> <ul> <li>Declarative updates: You define the desired state, and Kubernetes makes it happen.</li> <li>Rollouts and rollbacks: Easily update your application or revert to a previous version.</li> </ul>"},{"location":"kubernetes-architecture/#how-could-these-components-work-together","title":"How could these components work together?","text":"<ol> <li>You submit a deployment manifest via <code>kubectl apply -f</code>.</li> <li>The API Server receives the request.</li> <li>The Scheduler picks a suitable node.</li> <li>The Controller Manager ensures the desired state is maintained.</li> <li>The Kubelet on the chosen node pulls the container image and starts the pod.</li> <li>The pod creates the relevant containers as the manifest describes</li> <li>Kube-proxy ensures networking is set up so the pod can communicate.</li> </ol>"},{"location":"kubernetes-architecture/#minikube-architecture","title":"Minikube Architecture","text":"<p>During this workshop we will be demonstrating Kubernetes using Minikube to create clusters and deploy resources. Minikube is a tool that lets you run a single-node Kubernetes cluster locally on your machine. It\u2019s designed for developers and learners who want to experiment with Kubernetes without needing a full multi-node setup.</p>"},{"location":"kubernetes-architecture/#how-standard-kubernetes-architecture-maps-to-minikube","title":"How standard Kubernetes architecture maps to Minikube:","text":"Standard Kubernetes Minikube Control Plane Runs inside the Minikube VM/container Worker Node Same VM/container acts as the worker node Kubelet Runs inside Minikube API Server Accessible via <code>kubectl</code> on your host etcd, Scheduler, Controller Manager All run inside the Minikube VM <p>Minikube supports many standard Kubernetes features as well as third-party extensions in the form of addons.</p>"},{"location":"kubernetes-architecture/#key-differences","title":"Key Differences:","text":"<ul> <li>Single-node setup: Control plane and worker node are co-located.</li> <li>Simplified networking: Easier to manage locally.</li> <li>Ideal for testing: Lightweight and fast to spin up.</li> </ul>"},{"location":"kubernetes-architecture/#summary","title":"Summary","text":"<ul> <li>Kubernetes separates concerns between managing the cluster (control plane) and running workloads (worker nodes).</li> <li>Minikube mimics this architecture in a simplified, single-node environment.</li> <li>Understanding these components helps you debug, optimize, and scale your applications effectively.</li> </ul>"},{"location":"kubernetes-architecture/#kubernetes-architecture-overview","title":"Kubernetes Architecture Overview","text":"<p>The components of a Kubernetes cluster. Overview Components</p>"},{"location":"kubernetes-architecture/#further-reading","title":"\ud83d\udcda Further Reading","text":"<ul> <li>Kubernetes project website</li> <li>Minikube documentation</li> </ul>"},{"location":"lesson0-kubernetes-dashboard/","title":"Lesson 0: Kubernetes Dashboard","text":"<p>The Kubernetes Dashboard is a web-based UI providing cluster information and deployment status in Kubernetes.  It will give visual feedback for the commands you'll be running during the workshop and help you understand the state of a cluster at a glance. While the dashboard may be used to directly manage a Kubernetes cluster, we will take the more explicit approach to management with the Kubernetes CLI, <code>kubectl</code>.</p> <p>\u26a0\ufe0f Commands in the lessons should be run in a Linux/WSL/Mac OS terminal, or  a Windows equivalent (Command Prompt or Power shell)</p>"},{"location":"lesson0-kubernetes-dashboard/#dashboard-access","title":"Dashboard Access","text":"<p>minikube has built-in support for the Kubernetes Dashboard. First, start a cluster if you have not already:</p> <pre><code>minikube start\n</code></pre> <p>Then, launch the dashboard with</p> <pre><code>minikube dashboard\n</code></pre> <p>This should open the web UI in a browser window. Alternatively, run <code>minikube dashboard --url</code> and copy the URL. </p> <p>\u26a0\ufe0f  You will need to leave the terminal process open (or fork the command into the background) to maintain access to the dashboard.</p>"},{"location":"lesson0-kubernetes-dashboard/#dashboard-overview","title":"Dashboard Overview","text":"<p>The dashboard is organised into several sections. We'll focus on the parts immediately relevant for getting started: Workloads, Cluster Nodes and Namespaces. In subsequent lessons, we will also introduce ingress, storage volumes and config maps.</p>"},{"location":"lesson0-kubernetes-dashboard/#workloads","title":"Workloads","text":"<p>Workloads shows the applications running in your cluster, including</p> <ul> <li>Deployments: High-level specifications for running applications</li> <li>Pods: Provide instances of you  application (the smallest deployable units in Kubernetes)</li> <li>Replica Sets: Ensure the desired number of pods are running</li> </ul> <p>For now, Workloads will be mostly empty since we haven't deployed any applications.</p>"},{"location":"lesson0-kubernetes-dashboard/#cluster-information","title":"Cluster Information","text":"<p>Navigate to <code>Cluster &gt; Nodes</code> to view information about your minikube cluster. Here you'll see a single minikube node, which represents the virtual machine running your Kubernetes cluster.</p> <p>Clicking on the node name (minikube) will show detailed information including CPU and memory allocation, system information, and running pods. You'll notice several pods already running for essential system services, such as storage provision and network routing\u2014plus a pod for the dashboard.</p> <p> minikube system information in the dashboard (<code>Cluster &gt; Nodes &gt; minikube</code>)</p>"},{"location":"lesson0-kubernetes-dashboard/#namespaces","title":"Namespaces","text":"<p>The dropdown menu next to the search bar at the top of the dashboard allows you to filter by namespace. Namespaces are a fundamental Kubernetes concept. They provide a way to organise and isolate resources within a cluster. </p> <p>In this workshop, we will work in the default namespace, which is created automatically. In the real-world, you may want to use namespaces to divide resources between projects, teams or environments (e.g., <code>dev</code>, <code>prod</code>). You may find it helpful to explore the kube-system namespace  to see what's running behind the scenes</p>"},{"location":"lesson0-kubernetes-dashboard/#tips","title":"\ud83d\udca1 Tips","text":"<ul> <li>Keep the dashboard open to see the effect of <code>kubectl</code> commands in real-time</li> <li>Green typically mean healthy/running,   yellow  pending/updating, and    red an  error state</li> <li>Click on any resource name to get detailed information and logs</li> </ul>"},{"location":"lesson0-kubernetes-dashboard/#further-reading","title":"\ud83d\udcda Further Reading","text":"<ul> <li>Official Kubernetes Dashboard   Documentation</li> <li>Power-users may be interested in the k9s terminal-based   UI or the Lens IDE</li> </ul>"},{"location":"lesson1-kubechaos/","title":"Lesson 1: Your First Deployment","text":"<p>In this lesson we are going to deploy a simple web application, called Kubechaos, on a minikube cluster.  This will demonstrate core Kubernetes concepts including pods, deployments, and services.</p>"},{"location":"lesson1-kubechaos/#prerequisites","title":"Prerequisites","text":"<p>You will need a local clone of the Kubechaos repository:</p> <pre><code>git clone https://github.com/rosalindfranklininstitute/rsecon25-intro-to-kubernetes.git\ncd rsecon25-intro-to-kubernetes\n</code></pre> <p>Check your cluster from the previous lesson is still running (<code>minikube start</code> if it is not):</p> <pre><code>minikube status\n</code></pre>"},{"location":"lesson1-kubechaos/#building-the-container-image","title":"Building the Container Image","text":"<p>Kubernetes runs applications in containers, but does not handle building container images itself\u2014it expects images to already be available. Minikube provides a convenient build tool that allows us to create a Docker image (defined in <code>image/Dockerfile</code>) for the Kubechaos app:</p> <pre><code>minikube image build -t local/kubechaos:v1 image\n</code></pre> <p>The built image is stored in minikube's local registry, identified in the output of the command <code>minikube image ls</code> by the tag <code>local/kubchaos:v1</code>.</p>"},{"location":"lesson1-kubechaos/#inspecting-the-manifest","title":"Inspecting the Manifest","text":"<p>A Kubernetes manifest is a YAML file that defines the target state of resources in a cluster. If you open <code>deployment/manifests.yaml</code>, you'll see it contains definitions for:</p> <ul> <li>A Deployment (manages pods)</li> <li>A Service (provides networking)</li> <li>A ConfigMap (explored in lesson 3)</li> </ul> <p>Notice the image tag <code>local/kubechaos:v1</code> in the manifest matches what we just built.</p>"},{"location":"lesson1-kubechaos/#application-deployment","title":"Application Deployment","text":"<p>The <code>kubectl apply</code> command deploys resources in manifest files to a cluster:</p> <pre><code>kubectl apply -f deployment/manifests.yaml\n</code></pre> <p>For large applications, it can be useful to know when a pod is ready:</p> <pre><code>kubectl wait --for=condition=ready pod -l app=kubechaos\n</code></pre> <p>The <code>-l app=kubechaos</code> flag targets pods with the label <code>app=kubechaos</code> seen in the manifest.</p> <p>You can now view the app in your browser by using minkube's service command to create a proxy to the container:</p> <pre><code>minikube service kubechaos-svc\n</code></pre> <p>Open the returned URL in your browser\u2014every refresh is a new surprise \ud83c\udfb2</p>"},{"location":"lesson1-kubechaos/#pods-and-logs","title":"Pods and Logs","text":"<p>Let's examine what was created on the cluster. In the terminal, list the running pods:</p> <pre><code>kubectl get pods \n</code></pre> <p>You will get output similar to:</p> <pre><code>NAME                        READY   STATUS    RESTARTS   AGE\nkubechaos-6d7ddd9cf-lvczb   1/1     Running   0          3s\n</code></pre> <p>Pods are the smallest unit of Kubernetes deployment. They  represents one or more containers running together.  In this case, we have a Kubechaos pod with a single (1/1) container running. You can check the pod has also appeared in the Web Dashboard under <code>Workloads &gt; Pods</code>.</p> <p>To learn the status of the pod we can view the logs:</p> <pre><code>kubectl logs kubechaos-&lt;id&gt;\n</code></pre> <p>where you will need to replace <code>&lt;id&gt;</code> with the unique identifier  that was shown under <code>NAME</code> when you ran the <code>get pods</code> command. You will see a record of the node.js app starting inside the container:</p> <pre><code>&gt; kubechaos@1.0.0 start\n&gt; node app.js\n\nServer running at http://localhost:3000\n</code></pre> <p>Note that the URL here refers to an internal port of the container, which is different from the port the minikube proxy exposed on  your localhost for accessing the service from outside the cluster. In general Kubernetes keeps the internal container network separate from external access, and you need to explicitly configure how services can be reached from outside the cluster (see Ingress below).</p>"},{"location":"lesson1-kubechaos/#deletion-experiment","title":"Deletion Experiment","text":"<p>Let's see what happens if we delete the pod from the cluster:</p> <pre><code>kubectl delete pod &lt;pod-name&gt;\n</code></pre> <p>Now run <code>kubectl get pods</code> again, what do you notice?</p> <p>You will see that a new pod, with a different unique-identifier,  was started in place of the removed one. This self-healing is a key feature of Kubernetes' deployments.</p>"},{"location":"lesson1-kubechaos/#delving-into-deployments","title":"Delving into Deployments","text":"<p>A Deployment is a Kubernetes resource that manages the desired state of an application. Looking back at the manifest file (deployment/manifests.yaml), the Deployment section defined how many replicas of the application container should run, which image to use, and further configuration.  This is an example of a declarative approach: you declare the target state, and Kubernetes figures out how to attain\u2014and then maintain\u2014it.</p>"},{"location":"lesson1-kubechaos/#replica-sets","title":"Replica Sets","text":"<p>Deployments don't directly manage pods. Instead, they work through ReplicaSets which are responsible for creating the individual pods. In summary,</p> <p>Deployment \u2192 ReplicaSet \u2192 Pods</p> <p>Where Deployment defines the target state, ReplicaSet ensures the correct number of replicas are alive, and Pods are the actual App instances.</p>"},{"location":"lesson1-kubechaos/#self-healing-and-scaling","title":"Self-healing and Scaling","text":"<p>We have already seen self-healing in action: when a pod was deleted the ReplicaSet detected the live state (0 pods) didn't match the  desired state (1 pod) and so created a replacement. This automatic recovery ensures applications can remain available even when individual pods fail.</p> <p>Another key feature of Kubernetes' deployments is scaling. Suppose we want to scale up to three replicas to support more concurrent requests or ensure better availability.</p> <p>First, let's set up a watch to monitor the pods in real-time:</p> <pre><code>kubectl get pods -w\n</code></pre> <p>Next, in a new terminal, run the following <code>kubectl scale</code> command:</p> <pre><code>kubectl scale deployment kubechaos --replicas=3\n</code></pre> <p>In the first terminal you will see in two additional replicas being spun up immediately! You can verify the new state with <code>kubectl get deployment</code> or by reviewing the Deployments/Pods page in the Web Dashboard.</p>"},{"location":"lesson1-kubechaos/#ingress-production-ready-external-access","title":"Ingress: Production-Ready External Access","text":"<p>In networking terminology, \"ingress\" refers to incoming traffic, and \"egress\" outgoing traffic. For infrastructure and cloud computing, ingress describes how external clients access services running inside a protected network.</p> <p>You won't be surprised to learn that Ingress in Kubernetes is also a resource. Specifically, it defines rules for routing HTTP/HTTPS traffic from outside the cluster to services within it. These rules are implemented by a load balancer component (like nginx) called an Ingress Controller.  A simplified traffic flow is:</p> <pre><code>External Client \u2192 Ingress Controller + Rules \u2192 Service \u2192 Pod\n</code></pre> <p>where the Service groups pods running your application. </p>"},{"location":"lesson1-kubechaos/#beyond-minikube-service","title":"Beyond minikube service","text":"<p>Above, we used the <code>minikube service</code> command, which creates a temporary proxy from your local machine to the application containers. While convenient for development, this approach is limited to basic port forwarding.</p> <p>For production, you'll need the proper HTTPS routing with DNS, SSL/TLS termination and advanced load balancing provided by Kubernetes Ingress. Minikube supports Kubernetes Ingress with the <code>ingress</code> add-on (see Further Reading).</p>"},{"location":"lesson1-kubechaos/#further-reading","title":"\ud83d\udcda Further Reading","text":"<ul> <li>Official kubectl Quick Reference</li> <li>The Kubernetes Networking Guide </li> <li>Ingress DNS minikube add-on</li> </ul>"},{"location":"lesson2-kubechaos-extra/","title":"Lesson 2 Extension Task: Multiple Deployments","text":"<p>A Kubernetes cluster is not limited to running a single service or deployment. Let's try something a bit more advanced - running both the original and your modified version of the kubechaos application at the same time, splitting traffic between them (single service).</p>"},{"location":"lesson2-kubechaos-extra/#remove-previous-deployment","title":"Remove Previous Deployment","text":"<p>Before attempting the dual deployment, remove the deployment that is currently running:</p> <pre><code>kubectl delete deployment kubechaos\n</code></pre> <p>Check there are no deployments running with</p> <pre><code>kubectl get deployments\n</code></pre>"},{"location":"lesson2-kubechaos-extra/#update-your-manifest-for-dual-deployments","title":"Update Your Manifest for Dual Deployments","text":"<p>Open <code>deployment/manifests.yaml</code> and;</p> <ul> <li>Create an additional deployment called <code>kubechaos-custom</code>, which uses our newer version<code>local/kubechaos:v2</code>, with additional labels <code>spec.selector.matchLabels.version: custom</code> and <code>spec.template.metadata.labels: custom</code>.</li> <li>Update the original deployment to be called <code>kubechaos-original</code> with labels for <code>original</code>.</li> </ul> <p>Or simply replace <code>deployment/manifests.yaml</code> with this new specification:</p> deployment/manifests.yaml <pre><code># Original version deployment\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kubechaos-original\n  labels:\n    app: kubechaos\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kubechaos\n      version: original\n  template:\n    metadata:\n      labels:\n        app: kubechaos\n        version: original\n    spec:\n      containers:\n      - name: app\n        image: local/kubechaos:v1  # Original version\n        ports:\n        - containerPort: 3000\n---\n# Custom version deployment  \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kubechaos-custom\n  labels:\n    app: kubechaos\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kubechaos\n      version: custom\n  template:\n    metadata:\n      labels:\n        app: kubechaos\n        version: custom\n    spec:\n      containers:\n      - name: app\n        image: local/kubechaos:v2  # Your custom version\n        ports:\n        - containerPort: 3000\n---\n# Service targets both versions\napiVersion: v1\nkind: Service\nmetadata:\n  name: kubechaos-svc\nspec:\n  type: NodePort\n  selector:\n    app: kubechaos  # Unchanged\n  ports:\n  - name: kubechaos-port\n    protocol: TCP\n    port: 3000\n    targetPort: 3000\n</code></pre> <p>To distinguish the deployments, we gave them different names and their specification pods <code>version</code> labels. Note the  <code>Service</code> specification is unchanged. In particular, the <code>app: kubechaos</code> selector will match both deployments!</p>"},{"location":"lesson2-kubechaos-extra/#deploy-and-observe","title":"Deploy and Observe","text":"<p>After updating the manifest, apply the new configuration:</p> <pre><code>kubectl apply -f deployment/manifests.yaml\n</code></pre> <p>And watch pods being created:</p> <pre><code>kubectl get pods -w\n</code></pre> <p>Press <code>Ctrl+C</code> when you see both pods running,  and check the final state:</p> <pre><code>kubectl get deployments\n</code></pre> <p>You should now see a <code>kubechaos-original</code> and a <code>kubechaos-custom</code> deployment.  If we now re-run the <code>minikube service</code> command (note the URL port will have changed),</p> <pre><code>minikube service kubechaos-svc --url\n</code></pre> <p>you may be served either the original surprises or your new ones. More information on the pods associated with the service can be printed with</p> <pre><code>kubectl get endpointslices\n</code></pre> <p>You may need to open additional (private) browsing sessions in order to get served by the other pod. Keep refreshing!</p>"},{"location":"lesson2-kubechaos-extra/#questions","title":"\ud83e\udd14 Questions","text":"<ul> <li>Why might you consistently hit the same pod even with multiple refreshes? </li> <li>If you have hundreds of users visiting your site, how does Kubernetes decide   which pod serves each request?</li> <li>How could you ensure the new version serves three-quarters of requests on   average?</li> </ul> <p>The answer to these questions lies with Kubernetes Services and kube-proxy - components working behind the scenes that act as traffic directors. In particular, kube-proxy serves as a load balancer which, by default, cycles through pods sequentially (round-robin).</p> <p>This is what makes a multi-pod deployment appear like a single, reliable service, even though the work is actually distributed across multiple containers!</p> <p>For production systems, understanding and configuring load balancers is essential for reliability and performance.</p>"},{"location":"lesson2-kubechaos-update/","title":"Lesson 2: Updating the Kubechaos App","text":"<p>How do you update a running application without breaking it? In this lesson, we'll explore redeployment in Kubernetes by applying changes to both the application image and specification. </p>"},{"location":"lesson2-kubechaos-update/#step-1-customise-the-application","title":"Step 1: Customise the Application","text":"<p>Open <code>image/app.js</code> and find the <code>suprises</code> variable (line 7). This is a JavaScript array where each element is a string with HTML content:</p> <pre><code>const surprises = [\n  `&lt;h2&gt;\ud83c\udfaf Click the target!&lt;/h2&gt;\n   &lt;div style=\"font-size:100px;cursor:pointer;\" onclick=\"alert('You hit it! \ud83c\udf89')\"&gt;\ud83c\udfaf&lt;/div&gt;`,\n\n  `&lt;h2&gt;\ud83d\ude02 Joke of the moment&lt;/h2&gt;\n   &lt;p&gt;Why did the dolphin get a job in Kubernetes?&lt;br&gt;Because it already knew how to work in pods.&lt;/p&gt;`,\n\n  // ... more entries\n];\n</code></pre> <p>Your tasks:</p> <ol> <li>Add 2-3 of you own surprises with jokes or other HTML content</li> <li>Remove the original surprise elements</li> <li>Finally, locate the \"KubeChaos @ RSECon25!\" title and replace it with \"&lt;your-name&gt; @ RSECon25!\"</li> </ol> <p>\u26a0\ufe0f  JavaScript Array Syntax:</p> <ul> <li>Each element is wrapped in backticks <code>\\</code> (multi-line strings)</li> <li>Elements are separated by commas</li> </ul>"},{"location":"lesson2-kubechaos-update/#building-the-new-image","title":"Building the New Image","text":"<p>Once you've made your changes, build a new container image with a <code>v2</code> tag:</p> <pre><code>minikube image build -t local/kubechaos:v2 image\n</code></pre> <p>Verify your new image was created:</p> <pre><code>minikube image ls\n</code></pre> <p>You should see  both <code>local/kubechaos:v1</code> and  <code>local/kubechaos:v2</code> listed.</p>"},{"location":"lesson2-kubechaos-update/#step-2-update-and-redeploy","title":"Step 2: Update and Redeploy","text":"<p>Now let's update your deployment to use the new image.</p>"},{"location":"lesson2-kubechaos-update/#update-the-manifest","title":"Update the manifest","text":"<p>Open <code>deployment/manifests.yaml</code> and update the image tag used by the container:</p> <pre><code>    spec:\n      containers:\n      - name: app\n        image: local/kubechaos:v2  # Changed from v1\n</code></pre> <p>Make sure to save the file.</p>"},{"location":"lesson2-kubechaos-update/#redeploy-the-application","title":"Redeploy the Application:","text":"<p>Apply your changes to the cluster:</p> <pre><code>kubectl apply -f deployment/manifests.yaml\n</code></pre> <p>Check when the deployment is complete:</p> <pre><code>kubectl rollout status deployment kubechaos\n</code></pre> <p>\ud83d\udca1 If we had simply modified and rebuilt the <code>v1</code> image, it would have been sufficient to restart the deployment (<code>kubectl rollout restart deploy kubechaos</code>). Since we changed the manifest, however, a redeployment  is necessary. </p>"},{"location":"lesson2-kubechaos-update/#test-your-changes","title":"Test Your Changes","text":"<p>Return to the browser window/URL with the running application - on refresh you should now see your own jokes and custom title!</p> <p>If you closed the browser window, you can get the service URL from <code>minikube service kubechaos-svc --url</code> as before.</p>"},{"location":"lesson2-kubechaos-update/#further-reading","title":"\ud83d\udcda Further Reading","text":"<ul> <li>Deployments   in the official Kubernetes documentation</li> <li>42 Kubernetes   Projects for hands-on learning</li> </ul>"},{"location":"lesson3-config-maps/","title":"Lesson 3: Updating with ConfigMaps","text":"<p>In lesson 2 you learnt how to update the Kubechaos app by making changes to the source code and then easily redeploying the app. In this lesson we will show you a way of updating your application outside of modifying the code directly. This allows you to decouple environment specific configuration from your container images, leading to ease of update and portability.</p>"},{"location":"lesson3-config-maps/#what-is-a-configmap","title":"What is a ConfigMap","text":"<p>A ConfigMap is a Kubernetes API object which stores data in key-value pairs. They are used for non-confidential data only, for managing confidential data you can use Secrets. Further reading on secrets can be found here. </p> <p>Pods can use the information in ConfigMaps either as environmental variables or the ConfigMap can be mounted as a volume. In this tutorial we will go through both cases and how they can be applied. </p>"},{"location":"lesson3-config-maps/#configuring-the-style-with-environmental-variables","title":"Configuring the Style with Environmental variables","text":"<p>In web applications the style is often configured independently of the application code. Kubernetes offers an easy and useful way to update pods from ConfigMaps without having to redeploy anything or rebuild the container.</p> <p>We currently have a configMap running in our cluster. You can view it either through the minikube dashboard by clicking on ConfigMap in the side bar, or by running</p> <pre><code>kubectl describe configmap kubechaos-style\n\n</code></pre> <p>This ConfigMap controls the style of the website. We can change the colours and fonts without needing to change the underlying software of the container as you did in Lesson 2.</p> <p>We are now going to change the colors and border of the web application. To edit the ConfigMap type the following into a terminal</p> <pre><code>kubectl edit configmap kubechaos-style\n</code></pre> <p>Change the following variables:</p> <pre><code>  bg_color:  white\n  font_color: black\n  border_color: black\n  border_size: 4px\n  border_style: dashed\n\n</code></pre> <p>\u26a0\ufe0f  Note you will need to use specific variables for colors:  - they can be in hex rgb format e.g. #000000 or #0000ff  - or they can be in css names e.g. black or blue</p> <p>Refresh your web browser. What has happened?</p> <p>You will have noticed that your changes have not been applied, the styling remains the same. To get the colours to change run the following:</p> <pre><code>kubectl rollout restart deployment kubechaos\n</code></pre> <p>Refresh your web browser, what do you see now?</p>"},{"location":"lesson3-config-maps/#explanation","title":"Explanation","text":"<p>The variables that you edited in the ConfigMap are applied as environmental variables. To get the pod to pick up on it's new environment it needs to be remade. The quickest way to restart everything is to use the <code>kubectl rollout restart</code> command we used above.</p> <p>We will now look at <code>manifest.yml</code>. Please open up this file and scroll to the  block at line 22, to line 44. In this part of the deploymnet we set the <code>env</code> section of the container with values from the ConfigMap.</p> <pre><code>    spec:\n      containers:\n      - name: app\n        image: local/kubechaos:v1\n        ports:\n        - containerPort: 3000\n        env:\n        - name: BG_COLOR\n          valueFrom:\n            configMapKeyRef:\n              name: kubechaos-style\n              key: bg_color\n        - name: FONT_COLOR\n          valueFrom:\n            configMapKeyRef:\n              name: kubechaos-style\n              key: font_color\n        - name: BORDER_COLOR\n          valueFrom:\n            configMapKeyRef:\n              name: kubechaos-style\n              key: border_color\n        - name: BORDER_SIZE\n          valueFrom:\n            configMapKeyRef:\n              name: kubechaos-style\n              key: border_size\n        # can you edit this to add the BORDER_STYLE  env variable from the ConfigMap\n</code></pre> <p>Extra In <code>manifests.yaml</code> can you add the value of <code>border_style</code> to the enviromental variable <code>BORDER_STYLE</code> to change the border style, through the ConfigMap?</p> <p>In this section we injected variables from the ConfigMap into the pod as environmental variables to make changes without having to rebuild the image. This use case is ideal for applications that read configuration through environment variables. This method is straightforward and doesn't require file handling. You have to restart the container in order for any ConfigMap changes to take effect.</p> <p>In the next section we will look at mounting our configMap to the container as a volume. This method is used when applications are expecting configuration files rather than environmental variables.</p>"},{"location":"lesson3-config-maps/#configuring-the-style-with-a-css-file","title":"Configuring the style with a css file","text":"<p>Usually a website's style is configured through a stylesheet provided as a <code>.css</code> file, rather than with environmental variables. In this section we are going to look at another way to use ConfigMaps, mounting them as volumes into the pod.</p> <p>If you look at the ConfigMap we have deployed on our cluster either through the Minikube Dashboard or by running <code>kubectl describe configmap kubechaos-style</code> you will see that there is a definition of a css file in the ConfigMap:</p> <pre><code>style.css:\n----\nbody { font-family: 'sans-serif';\n       text-align: center;\n       margin-top: 5rem;}\n\n</code></pre> <p>Now let's edit these variables in the ConfigMap keeping the structure of the file intact:</p> <p>\u26a0\ufe0f  Note you will need to use specific variables for <code>font-family and</code>text-align<code>:  -</code>text-align<code>can be</code>center<code>,</code>right<code>,</code>left<code>-</code>font-family<code>has to belong to the websafe fonts e.g.</code>serif<code>,</code>arial<code>,</code>garamond`</p> <pre><code>kubectl edit configmap kubechaos-style\n</code></pre> <p>Refresh your browser? What happens now? You will see the changes you made will be applied immediately on refresh without restarting the deployment.</p>"},{"location":"lesson3-config-maps/#explanation_1","title":"Explanation","text":"<p>Here we are mounting a file as a volume into the pod. The file is being written by the values in the in the ConfigMap. When we change the values they are immediately picked up by the pod without it being restarted. If you open the <code>manifest.yml</code> and scroll to line 44 to 54 you will see:</p> <p>```   container:             ...         volumeMounts:         - name: style-env           mountPath: \"/src/public/\"           readOnly: true       volumes:       - name: style-env         configMap:           name: kubechaos-style           items:             - key: \"style.css\"               path: \"style.css\"</p> <pre><code>\nThis section of the deployment creates a volume called `style-env` and then mounts it as a volume in the container. This volume contains the `style.css` file and is mounted on the path the application expects.\n\nTo see the mainfest of the original ConfigMap (before our edits) you can scroll down to line 73 in `manifests.yml`:\n\n</code></pre> <p>apiVersion: v1 kind: ConfigMap metadata:   name: kubechaos-style data:   bg_color:  white   font_color: black   border_color: black   border_size: 4px   border_style: dashed</p> <p>style.css: |     body { font-family: 'sans-serif';            text-align: center;            margin-top: 5rem;            }</p> <p>``` For a production system you can version control your changes to a ConfigMap as a manifest and apply it to your cluster.</p>"},{"location":"lesson3-config-maps/#further-reading","title":"\ud83d\udcda Further Reading","text":"<ul> <li>Official Kubernetes documentation on ConfigMaps</li> <li>Learn about Secrets</li> </ul>"},{"location":"lesson4-helm/","title":"Lesson 4: Helm Charts","text":""},{"location":"lesson4-helm/#introduction","title":"Introduction","text":"<p>Helm is a package manager for Kubernetes that provides a  convenient way to share and install community applications. By packaging manifests into reusable 'Charts', complex projects can be installed with a single command, including any dependencies. Helm handles versioning and allows customisation through templatable values.</p> <p>In this lesson, we'll deploy a community application available as a Helm chart to our minikube cluster. </p> <p>\u26a0\ufe0f  Security</p> <p>Like all code on the internet, Helm charts can contain malicious content. Only install Helm charts from trusted sources. Vetting charts using Helm's <code>template</code> and <code>verify</code> commands and other best practices  are discussed in the <code>sysdig</code> article in Further Reading. </p>"},{"location":"lesson4-helm/#prerequisites","title":"Prerequisites","text":"<p>On Linux/WSL, Helm can be installed as a snap package</p> <pre><code>sudo snap install helm --classic\n</code></pre> <p>On macOS, it is available through Homebrew</p> <pre><code>brew install helm\n</code></pre> <p>Other Windows users can use the Chocolately package manager:</p> <pre><code>choco install kubernetes-helm\n</code></pre> <p>You can verify your installation by running <code>helm version</code>.</p>"},{"location":"lesson4-helm/#deploying-mocktail-with-helm","title":"\ud83c\udf79 Deploying Mocktail with Helm","text":"<p>Mocktail is a minimalist server that allows you to define and test custom API endpoints. We'll use it to demonstrate deploying a collection of kubernetes manifests to our cluster using a Helm chart.</p>"},{"location":"lesson4-helm/#understanding-helm-repositories","title":"Understanding Helm Repositories","text":"<p>Helm Charts can be found in two main ways:</p> <ul> <li>On community repositories like Artifact Hub, with many projects</li> <li>On individual repositories e.g. on GitHub for specific projects</li> </ul> <p>Mocktail provides its own Helm repository, which we can add to Helm with</p> <pre><code>helm repo add hhaluk https://huseyinnurbaki.github.io/charts/\n\n</code></pre> <p>It's a good idea to periodically get Helm to check for updates from added repositories: </p> <pre><code>helm repo update\n</code></pre>"},{"location":"lesson4-helm/#deploying-mocktail","title":"Deploying Mocktail","text":"<p>Having added the Mocktail helm repository, the application can be deployed to our minikube cluster with</p> <pre><code>helm install mocktail hhaluk/mocktail -n mocktail --create-namespace\n</code></pre> <p>That's it! In the background, Helm organised:</p> <ul> <li>Downloading the chart and generating all necessary manifests</li> <li>Creating a namespace for the manifests to be deployed to</li> <li>Creating deployments and services</li> <li>Starting the application</li> </ul>"},{"location":"lesson4-helm/#access-monktail","title":"Access Monktail","text":"<p>Query the service</p> <pre><code>minikube service mocktail-svc --url -n mocktail\n</code></pre> <p>The URL should take you to the Mocktail dashboard.</p>"},{"location":"lesson4-helm/#optional-test-the-mock-api","title":"Optional: Test the Mock API","text":"<p>Try creating a custom endpoint in the dashboard:</p> <ol> <li>Add a new GET endpoint: <code>/surprise</code></li> <li>Set the response:</li> </ol> <pre><code>{\n      \"message\": \"Hello from Kubernetes!\",\n      \"pod\": \"mocktail-pod\",\n      \"surprise\": \"\ud83c\udfb2\"\n}\n</code></pre> <p>\u00a0  \u00a0 3. Test it with curl from a Terminal:</p> <pre><code>curl &lt;mocktail-dashboard-url:PORT&gt;/mocktail/surprise\n</code></pre> <p>\ud83d\udca1 The <code>jq</code> command can be used to pretty-print the JSON  returned by the request: <code>curl .../surprise | jq</code></p>"},{"location":"lesson4-helm/#customising-charts-with-values","title":"Customising Charts with Values","text":"<p>A powerful feature of Helm is the ability to customise applications  with your own parameters. First, view available configuration options for Mocktail:</p> <pre><code>helm show values hhaluk/mocktail\n</code></pre> <p>Let's override the default <code>replicaCount: 1</code> to have three replicas for the service. This can be done using the <code>--set OPTION=VALUE</code> syntax for the install/upgrade command:</p> <pre><code>helm upgrade mocktail hhaluk/mocktail --set replicaCount=3 -n mocktail\n</code></pre> <p>For larger number of changes, you can write a <code>custom-values.yaml</code> file and apply them with helm. We have provided a file at helm/custom-values.yaml for updating the existing helm release with an ingress. </p> <pre><code>helm upgrade -i my-mocktail hhaluk/mocktail -n my-mocktail --create-namespace -f helm/custom-values.yaml\n</code></pre> <p>The above command can be used for a first time install of a helm release or to upgrade an existing release due to the <code>-i</code> flag.</p> <p>This upgrade has changed the container port that the service listens on.</p> <p>There are a large number of  community charts covering thousands of  web and infrastructure projects. Charts on Artifact Hub may be searched directly from the command line with</p> <pre><code>helm search hub &lt;search-term&gt;\n</code></pre> <p>You can also search in any repositories you have added. For example, first adding the popular Bitnami Library:</p> <pre><code>helm repo add bitnami https://charts.bitnami.com/bitnami\nhelm repo update\n</code></pre> <p>Then</p> <pre><code>helm search repo &lt;search-term&gt;\n</code></pre>"},{"location":"lesson4-helm/#optional-cleaning-up-helm-charts","title":"(Optional) Cleaning up helm charts","text":"<p>Helm comes with a handy process to also remove resources that have been added to the cluster. We can clean up everything we deployed  during this lession using: </p> <pre><code>helm uninstall mocktail -n mocktail\nhelm uninstall my-mocktail -n my-mocktail\n</code></pre> <p>You can check that the resources have been removed by using <code>kubectl</code>  or checking for the helm releases:</p> <pre><code>helm list -n mocktail\nhelm list -n my-mocktail\n</code></pre> <p>Note: This will not remove the namespace itself for that you need to separately run `kubectl delete namespace mocktail my-mocktail</p> <p>\ud83d\udcda Further Reading </p> <ul> <li>Helm Documentation</li> <li>Artifact Hub</li> <li>Helm security and best   practices</li> </ul>"},{"location":"why-kubernetes/","title":"Why kubernetes","text":"<p>TL;DR</p> <p>Docker compose is recommended if you have a single project with a few services for a single host. The complexity of Kuberentes is recommened if you have more than one application that you want to scale of have in high availability. This tutorial will demonstrate some of these features of Kubernetes and whether you want to consider using it in your project.</p> <p>A more in depth comparison is provided here:</p> <ul> <li> <p>Scalability and High Availability:         Kubernetes excels in large-scale environments by distributing containers across multiple nodes, ensuring high availability. If a node fails, others can take over seamlessly.         Docker Compose is limited to a single host, making it less suitable for production or scalable applications.</p> </li> <li> <p>Self-Healing and Reliability:          Kubernetes offers robust self-healing capabilities, automatically restarting failed containers and rescheduling them on healthy nodes.         Docker Compose has basic restart policies but lacks the advanced features of Kubernetes.</p> </li> <li> <p>Declarative Configuration and Rolling Updates:         Both use YAML files for configuration, but Kubernetes supports more complex setups and rolling updates without downtime.</p> </li> <li> <p>Resource Management:         Kubernetes provides fine-grained control over CPU, GPU and memory resources, ensuring efficient utilization across clusters.         Docker Compose offers basic resource limits, which may not be sufficient for large deployments.</p> </li> <li> <p>Networking:          Kubernetes supports sophisticated networking with pods, services, and ingress controllers, enabling advanced communication and external access.         Docker Compose uses a simpler network setup suitable for smaller applications.</p> </li> <li> <p>Security:         Kubernetes includes RBAC and network policies for enhanced security in large-scale deployments.         Docker Compose relies on the host's security measures, which may be less robust.</p> </li> <li> <p>Extensibility and Ecosystem:         Kubernetes has a vast ecosystem with CRDs and third-party tools for extensibility, offering more features beyond the basics.         Docker Compose lacks such extensive extension capabilities.</p> </li> <li> <p>Stateful Applications:          Kubernetes effectively manages stateful applications using StatefulSets, providing persistent identities and storage.         Docker Compose handles some stateful apps but isn't as robust for distributed systems.</p> </li> <li> <p>Backup and Restore:         Kubernetes simplifies data management with PersistentVolumes and ConfigMaps.         Docker Compose requires manual handling of volumes and data.</p> </li> <li> <p>Scalability Testing:         Kubernetes allows easy horizontal scaling by adjusting replicas based on load without downtime.         Scaling in Docker Compose is less seamless, typically requiring more manual intervention.</p> </li> <li> <p>Simplicity vs. Complexity:         Docker Compose is ideal for small projects or development due to its simplicity and lightweight setup.         Kubernetes, while more complex, is better suited for production environments requiring advanced features.</p> </li> </ul> <p>This text was produced with the help of deepseek-r1 from the Ollama project https://github.com/ollama/ollama </p>"}]}